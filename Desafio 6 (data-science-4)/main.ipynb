{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codenation - Data Science\n",
    "<pre>Autor: Leonardo Sim√µes</pre>\n",
    "\n",
    "## Desafio 6 - Feature engineering\n",
    "\n",
    "\n",
    "Neste desafio vamos praticar feature engineering, a arte de processar vari√°veis do data set a fim de torn√°-las mais adequadas aos algoritmos de ML e produzir melhores resultados, um dos processos mais importantes e trabalhosos de ML.\n",
    "\n",
    "Utilizaremos o _data set_ [Countries of the world](https://www.kaggle.com/fernandol/countries-of-the-world), que cont√©m dados sobre os 227 pa√≠ses do mundo com informa√ß√µes sobre tamanho da popula√ß√£o, √°rea, imigra√ß√£o e setores de produ√ß√£o.\n",
    "\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "O objetivo deste desafio √© adquirir conhecimento e pr√°tica nas ferramentas mais usuais de engenharia de vari√°veis. Com o dom√≠nio apropriado das t√©cnicas b√°sicas, como one-hot encoding, normaliza√ß√£o e padronia√ß√£o, o analista est√° mais bem preparado para conduzir uma etapa de preprocessamento dos dados que traga bons resultados da aplica√ß√£o dos algoritmos de ML.\n",
    "\n",
    "\n",
    "### T√≥picos\n",
    "\n",
    "Neste desafios n√≥s vamos explorar:\n",
    "- Feature engineering\n",
    "- Processamento de texto\n",
    "\n",
    "### Quest√µes\n",
    "<pre>\n",
    "1) Quais s√£o as regi√µes (vari√°vel Region) presentes no data set_? \n",
    "Retorne uma lista com as regi√µes √∫nicas do _data set com os espa√ßos √† frente e atr√°s da string removidos \n",
    "(mas mantenha pontua√ß√£o: ponto, h√≠fen etc) e ordenadas em ordem alfab√©tica. \n",
    "\n",
    "2) Discretizando a vari√°vel Pop_density em 10 intervalos com KBinsDiscretizer, seguindo o encode ordinal \n",
    "e estrat√©gia quantile, quantos pa√≠ses se encontram acima do 90¬∫ percentil? Responda como um √∫nico escalar \n",
    "inteiro.\n",
    "\n",
    "3) Se codificarmos as vari√°veis Region e Climate usando _one-hot encoding_, quantos novos atributos seriam \n",
    "criados? Responda como um √∫nico escalar.\n",
    "\n",
    "4) Ap√≥s aplicado o pipeline descrito, aplique o mesmo pipeline (ou ColumnTransformer) a outros dados. \n",
    "Qual o valor da vari√°vel Arable ap√≥s o _pipeline_? \n",
    "Responda como um √∫nico float arredondado para tr√™s casas decimais.\n",
    "\n",
    "5) Descubra o n√∫mero de outliers da vari√°vel Net_migration segundo o m√©todo do _boxplot_, ou seja, \n",
    "usando a l√≥gica: ùë•‚àâ[ùëÑ1‚àí1.5√óIQR,ùëÑ3+1.5√óIQR]‚áíùë• √© outlier que se encontram no grupo inferior e no grupo superior.\n",
    "Voc√™ deveria remover da an√°lise as observa√ß√µes consideradas outliers segundo esse m√©todo? \n",
    "Responda como uma tupla de tr√™s elementos (outliers_abaixo, outliers_acima, removeria?) ((int, int, bool)).\n",
    "\n",
    "6) Considere carregar as seguintes categorias e o dataset newsgroups:\n",
    "categories = ['sci.electronics', 'comp.graphics', 'rec.motorcycles']\n",
    "newsgroup = fetch_20newsgroups(subset=\"train\", categories=categories, shuffle=True, random_state=42)\n",
    "Aplique CountVectorizer ao data set newsgroups e descubra o n√∫mero de vezes que a palavra phone aparece \n",
    "no corpus. Responda como um √∫nico escalar.\n",
    "\n",
    "7) Aplique TfidfVectorizer ao data set newsgroups e descubra o TF-IDF da palavra phone. \n",
    "Responda como um √∫nico escalar arredondado para tr√™s casas decimais.\n",
    "</pre>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Setup_ geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.feature_extraction.text import (CountVectorizer, TfidfTransformer, TfidfVectorizer)\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, Binarizer, KBinsDiscretizer,\n",
    "    MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.datasets import load_digits, fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "figsize(12, 8)\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "countries = pd.read_csv(\"countries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Population</th>\n",
       "      <th>Area</th>\n",
       "      <th>Pop_density</th>\n",
       "      <th>Coastline_ratio</th>\n",
       "      <th>Net_migration</th>\n",
       "      <th>Infant_mortality</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Literacy</th>\n",
       "      <th>Phones_per_1000</th>\n",
       "      <th>Arable</th>\n",
       "      <th>Crops</th>\n",
       "      <th>Other</th>\n",
       "      <th>Climate</th>\n",
       "      <th>Birthrate</th>\n",
       "      <th>Deathrate</th>\n",
       "      <th>Agriculture</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>ASIA (EX. NEAR EAST)</td>\n",
       "      <td>31056997</td>\n",
       "      <td>647500</td>\n",
       "      <td>48,0</td>\n",
       "      <td>0,00</td>\n",
       "      <td>23,06</td>\n",
       "      <td>163,07</td>\n",
       "      <td>700.0</td>\n",
       "      <td>36,0</td>\n",
       "      <td>3,2</td>\n",
       "      <td>12,13</td>\n",
       "      <td>0,22</td>\n",
       "      <td>87,65</td>\n",
       "      <td>1</td>\n",
       "      <td>46,6</td>\n",
       "      <td>20,34</td>\n",
       "      <td>0,38</td>\n",
       "      <td>0,24</td>\n",
       "      <td>0,38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "      <td>3581655</td>\n",
       "      <td>28748</td>\n",
       "      <td>124,6</td>\n",
       "      <td>1,26</td>\n",
       "      <td>-4,93</td>\n",
       "      <td>21,52</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>86,5</td>\n",
       "      <td>71,2</td>\n",
       "      <td>21,09</td>\n",
       "      <td>4,42</td>\n",
       "      <td>74,49</td>\n",
       "      <td>3</td>\n",
       "      <td>15,11</td>\n",
       "      <td>5,22</td>\n",
       "      <td>0,232</td>\n",
       "      <td>0,188</td>\n",
       "      <td>0,579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>32930091</td>\n",
       "      <td>2381740</td>\n",
       "      <td>13,8</td>\n",
       "      <td>0,04</td>\n",
       "      <td>-0,39</td>\n",
       "      <td>31</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>70,0</td>\n",
       "      <td>78,1</td>\n",
       "      <td>3,22</td>\n",
       "      <td>0,25</td>\n",
       "      <td>96,53</td>\n",
       "      <td>1</td>\n",
       "      <td>17,14</td>\n",
       "      <td>4,61</td>\n",
       "      <td>0,101</td>\n",
       "      <td>0,6</td>\n",
       "      <td>0,298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>57794</td>\n",
       "      <td>199</td>\n",
       "      <td>290,4</td>\n",
       "      <td>58,29</td>\n",
       "      <td>-20,71</td>\n",
       "      <td>9,27</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>97,0</td>\n",
       "      <td>259,5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>22,46</td>\n",
       "      <td>3,27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>71201</td>\n",
       "      <td>468</td>\n",
       "      <td>152,1</td>\n",
       "      <td>0,00</td>\n",
       "      <td>6,6</td>\n",
       "      <td>4,05</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>100,0</td>\n",
       "      <td>497,2</td>\n",
       "      <td>2,22</td>\n",
       "      <td>0</td>\n",
       "      <td>97,78</td>\n",
       "      <td>3</td>\n",
       "      <td>8,71</td>\n",
       "      <td>6,25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Country                               Region  Population     Area  \\\n",
       "0     Afghanistan         ASIA (EX. NEAR EAST)             31056997   647500   \n",
       "1         Albania   EASTERN EUROPE                          3581655    28748   \n",
       "2         Algeria   NORTHERN AFRICA                        32930091  2381740   \n",
       "3  American Samoa   OCEANIA                                   57794      199   \n",
       "4         Andorra   WESTERN EUROPE                            71201      468   \n",
       "\n",
       "  Pop_density Coastline_ratio Net_migration Infant_mortality      GDP  \\\n",
       "0        48,0            0,00         23,06           163,07    700.0   \n",
       "1       124,6            1,26         -4,93            21,52   4500.0   \n",
       "2        13,8            0,04         -0,39               31   6000.0   \n",
       "3       290,4           58,29        -20,71             9,27   8000.0   \n",
       "4       152,1            0,00           6,6             4,05  19000.0   \n",
       "\n",
       "  Literacy Phones_per_1000 Arable Crops  Other Climate Birthrate Deathrate  \\\n",
       "0     36,0             3,2  12,13  0,22  87,65       1      46,6     20,34   \n",
       "1     86,5            71,2  21,09  4,42  74,49       3     15,11      5,22   \n",
       "2     70,0            78,1   3,22  0,25  96,53       1     17,14      4,61   \n",
       "3     97,0           259,5     10    15     75       2     22,46      3,27   \n",
       "4    100,0           497,2   2,22     0  97,78       3      8,71      6,25   \n",
       "\n",
       "  Agriculture Industry Service  \n",
       "0        0,38     0,24    0,38  \n",
       "1       0,232    0,188   0,579  \n",
       "2       0,101      0,6   0,298  \n",
       "3         NaN      NaN     NaN  \n",
       "4         NaN      NaN     NaN  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_column_names = [\n",
    "    \"Country\", \"Region\", \"Population\", \"Area\", \"Pop_density\", \"Coastline_ratio\",\n",
    "    \"Net_migration\", \"Infant_mortality\", \"GDP\", \"Literacy\", \"Phones_per_1000\",\n",
    "    \"Arable\", \"Crops\", \"Other\", \"Climate\", \"Birthrate\", \"Deathrate\", \"Agriculture\",\n",
    "    \"Industry\", \"Service\"\n",
    "]\n",
    "\n",
    "countries.columns = new_column_names\n",
    "\n",
    "countries.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observa√ß√µes\n",
    "\n",
    "Esse _data set_ ainda precisa de alguns ajustes iniciais. Primeiro, note que as vari√°veis num√©ricas est√£o usando v√≠rgula como separador decimal e est√£o codificadas como strings. Corrija isso antes de continuar: transforme essas vari√°veis em num√©ricas adequadamente.\n",
    "\n",
    "Al√©m disso, as vari√°veis `Country` e `Region` possuem espa√ßos a mais no come√ßo e no final da string. Voc√™ pode utilizar o m√©todo `str.strip()` para remover esses espa√ßos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lise dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliando as colunas do dataframe por tipo e valores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'Region', 'Population', 'Area', 'Pop_density',\n",
       "       'Coastline_ratio', 'Net_migration', 'Infant_mortality', 'GDP',\n",
       "       'Literacy', 'Phones_per_1000', 'Arable', 'Crops', 'Other', 'Climate',\n",
       "       'Birthrate', 'Deathrate', 'Agriculture', 'Industry', 'Service'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 227 entries, 0 to 226\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Country           227 non-null    object \n",
      " 1   Region            227 non-null    object \n",
      " 2   Population        227 non-null    int64  \n",
      " 3   Area              227 non-null    int64  \n",
      " 4   Pop_density       227 non-null    object \n",
      " 5   Coastline_ratio   227 non-null    object \n",
      " 6   Net_migration     224 non-null    object \n",
      " 7   Infant_mortality  224 non-null    object \n",
      " 8   GDP               226 non-null    float64\n",
      " 9   Literacy          209 non-null    object \n",
      " 10  Phones_per_1000   223 non-null    object \n",
      " 11  Arable            225 non-null    object \n",
      " 12  Crops             225 non-null    object \n",
      " 13  Other             225 non-null    object \n",
      " 14  Climate           205 non-null    object \n",
      " 15  Birthrate         224 non-null    object \n",
      " 16  Deathrate         223 non-null    object \n",
      " 17  Agriculture       212 non-null    object \n",
      " 18  Industry          211 non-null    object \n",
      " 19  Service           212 non-null    object \n",
      "dtypes: float64(1), int64(2), object(17)\n",
      "memory usage: 35.6+ KB\n"
     ]
    }
   ],
   "source": [
    "countries.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As colunas 'Country' e 'Region' ser√£o formatadas para remover espa√ßos no in√≠cio e fim de cada valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_qualitativas = ['Country', 'Region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>ASIA (EX. NEAR EAST)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>OCEANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Country                Region\n",
       "0     Afghanistan  ASIA (EX. NEAR EAST)\n",
       "1         Albania        EASTERN EUROPE\n",
       "2         Algeria       NORTHERN AFRICA\n",
       "3  American Samoa               OCEANIA\n",
       "4         Andorra        WESTERN EUROPE"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for coluna in colunas_qualitativas:\n",
    "    countries[coluna] = countries[coluna].apply(lambda s : s.strip())\n",
    "\n",
    "countries[colunas_qualitativas].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As colunas que s√£o do tipo 'object' ('string') que representa valores float ser√£o formatadas alterando o separador ',' para '.', e depois alterando seu tipo para 'float64'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pop_density', 'Coastline_ratio', 'Net_migration', 'Infant_mortality',\n",
       "       'Literacy', 'Phones_per_1000', 'Arable', 'Crops', 'Other', 'Climate',\n",
       "       'Birthrate', 'Deathrate', 'Agriculture', 'Industry', 'Service'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colunas_quantitativas_string = countries.select_dtypes(include=['object']).columns[2:]\n",
    "colunas_quantitativas_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coluna in colunas_quantitativas_string:\n",
    "    countries[coluna] = countries[coluna].str.replace(',', '.')\n",
    "    countries[coluna] = countries[coluna].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As colunas colunas com valores 'int64' ser√£o convertidas para 'float64' a fim de facilitar alguns c√°lculos posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Population', 'Area'], dtype='object')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colunas_quantitativas_int = countries.select_dtypes(include=['int64']).columns\n",
    "colunas_quantitativas_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coluna in colunas_quantitativas_int:\n",
    "    countries[coluna] = countries[coluna].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valores ausentes NaN de colunas quantitativas ser√£o substitu√≠dos por 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Population', 'Area', 'Pop_density', 'Coastline_ratio', 'Net_migration',\n",
       "       'Infant_mortality', 'GDP', 'Literacy', 'Phones_per_1000', 'Arable',\n",
       "       'Crops', 'Other', 'Climate', 'Birthrate', 'Deathrate', 'Agriculture',\n",
       "       'Industry', 'Service'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colunas_quantitativas = countries.select_dtypes(include=['float64', 'int64']).columns\n",
    "colunas_quantitativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(colunas_quantitativas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quest√£o 1\n",
    "\n",
    "Quais s√£o as regi√µes (vari√°vel `Region`) presentes no _data set_? Retorne uma lista com as regi√µes √∫nicas do _data set_ com os espa√ßos √† frente e atr√°s da string removidos (mas mantenha pontua√ß√£o: ponto, h√≠fen etc) e ordenadas em ordem alfab√©tica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASIA (EX. NEAR EAST)',\n",
       " 'BALTICS',\n",
       " 'C.W. OF IND. STATES',\n",
       " 'EASTERN EUROPE',\n",
       " 'LATIN AMER. & CARIB',\n",
       " 'NEAR EAST',\n",
       " 'NORTHERN AFRICA',\n",
       " 'NORTHERN AMERICA',\n",
       " 'OCEANIA',\n",
       " 'SUB-SAHARAN AFRICA',\n",
       " 'WESTERN EUROPE']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q1():\n",
    "    regions = countries.Region.unique()\n",
    "    regions = np.sort(regions)\n",
    "    \n",
    "    return list(regions)\n",
    "\n",
    "q1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quest√£o 2\n",
    "\n",
    "Discretizando a vari√°vel `Pop_density` em 10 intervalos com `KBinsDiscretizer`, seguindo o encode `ordinal` e estrat√©gia `quantile`, quantos pa√≠ses se encontram acima do 90¬∫ percentil? Responda como um √∫nico escalar inteiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q2():\n",
    "    pop_density = countries[['Pop_density']]\n",
    "    discretizer = KBinsDiscretizer(n_bins = 10, encode = 'ordinal', strategy = 'quantile')\n",
    "    discretizer.fit(pop_density)\n",
    "    scores = discretizer.transform(pop_density)\n",
    "    \n",
    "    return int((scores >= 9).sum())\n",
    "\n",
    "q2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quest√£o 3\n",
    "\n",
    "Se codificarmos as vari√°veis `Region` e `Climate` usando _one-hot encoding_, quantos novos atributos seriam criados? Responda como um √∫nico escalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q3():\n",
    "    countries_r_c = countries.copy()\n",
    "    countries_r_c = countries_r_c[['Region', 'Climate']]\n",
    "    countries_r_c['Region'] = countries_r_c['Region'].fillna(\"\")\n",
    "    countries_r_c['Climate'] = countries_r_c['Climate'].fillna(0)\n",
    "    \n",
    "    encoder = OneHotEncoder(sparse = False).fit_transform(countries_r_c[['Region', 'Climate']]) \n",
    "    \n",
    "    return int(encoder.shape[1])\n",
    "\n",
    "q3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quest√£o 4\n",
    "\n",
    "Aplique o seguinte _pipeline_:\n",
    "\n",
    "1. Preencha as vari√°veis do tipo `int64` e `float64` com suas respectivas medianas.\n",
    "2. Padronize essas vari√°veis.\n",
    "\n",
    "Ap√≥s aplicado o _pipeline_ descrito acima aos dados (somente nas vari√°veis dos tipos especificados), aplique o mesmo _pipeline_ (ou `ColumnTransformer`) ao dado abaixo. Qual o valor da vari√°vel `Arable` ap√≥s o _pipeline_? Responda como um √∫nico float arredondado para tr√™s casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_country = [\n",
    "    'Test Country', 'NEAR EAST', -0.19032480757326514,\n",
    "    -0.3232636124824411, -0.04421734470810142, -0.27528113360605316,\n",
    "    0.13255850810281325, -0.8054845935643491, 1.0119784924248225,\n",
    "    0.6189182532646624, 1.0074863283776458, 0.20239896852403538,\n",
    "    -0.043678728558593366, -0.13929748680369286, 1.3163604645710438,\n",
    "    -0.3699637766938669, -0.6149300604558857, -0.854369594993175,\n",
    "    0.263445277972641, 0.5712416961268142\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_country[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(colunas_quantitativas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_copy = countries[colunas_quantitativas].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.047"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q4():\n",
    "    num_pipeline = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                                   ('standard_scaler', StandardScaler())])\n",
    "    pipeline_transformation = num_pipeline.fit_transform(countries[colunas_quantitativas])\n",
    "    test_country_transform = num_pipeline.transform([test_country[2:]])\n",
    "    \n",
    "    return round(test_country_transform[:,countries.columns.get_loc(\"Arable\")-2][0],3)\n",
    "\n",
    "q4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quest√£o 5\n",
    "\n",
    "Descubra o n√∫mero de _outliers_ da vari√°vel `Net_migration` segundo o m√©todo do _boxplot_, ou seja, usando a l√≥gica:\n",
    "\n",
    "$$x \\notin [Q1 - 1.5 \\times \\text{IQR}, Q3 + 1.5 \\times \\text{IQR}] \\Rightarrow x \\text{ √© outlier}$$\n",
    "\n",
    "que se encontram no grupo inferior e no grupo superior.\n",
    "\n",
    "Voc√™ deveria remover da an√°lise as observa√ß√µes consideradas _outliers_ segundo esse m√©todo? Responda como uma tupla de tr√™s elementos `(outliers_abaixo, outliers_acima, removeria?)` ((int, int, bool))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      23.06\n",
       "1      -4.93\n",
       "2      -0.39\n",
       "3     -20.71\n",
       "4       6.60\n",
       "       ...  \n",
       "222     2.98\n",
       "223      NaN\n",
       "224     0.00\n",
       "225     0.00\n",
       "226     0.00\n",
       "Name: Net_migration, Length: 227, dtype: float64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries['Net_migration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 26, False)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q5():\n",
    "    net_migrations = countries['Net_migration'].dropna()\n",
    "    q1, q3 = np.quantile(net_migrations, .25), np.quantile(net_migrations, .75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    non_outlier_interval_iqr = [q1 - 1.5 * iqr, q3 + 1.5 * iqr]\n",
    "\n",
    "    outliers_above = net_migrations[net_migrations > non_outlier_interval_iqr[1]]\n",
    "    outliers_below = net_migrations[net_migrations < non_outlier_interval_iqr[0]]\n",
    "    \n",
    "    return (len(outliers_below), len(outliers_above), False)\n",
    "q5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quest√£o 6\n",
    "Para as quest√µes 6 e 7 utilize a biblioteca `fetch_20newsgroups` de datasets de test do `sklearn`\n",
    "\n",
    "Considere carregar as seguintes categorias e o dataset `newsgroups`:\n",
    "\n",
    "```\n",
    "categories = ['sci.electronics', 'comp.graphics', 'rec.motorcycles']\n",
    "newsgroup = fetch_20newsgroups(subset=\"train\", categories=categories, shuffle=True, random_state=42)\n",
    "```\n",
    "\n",
    "\n",
    "Aplique `CountVectorizer` ao _data set_ `newsgroups` e descubra o n√∫mero de vezes que a palavra _phone_ aparece no corpus. Responda como um √∫nico escalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['sci.electronics', 'comp.graphics', 'rec.motorcycles']\n",
    "newsgroup = fetch_20newsgroups(subset=\"train\", categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q6():\n",
    "    count_vectorizer = CountVectorizer() \n",
    "    newsgroup_counts = count_vectorizer.fit_transform(newsgroup.data)\n",
    "    words = pd.DataFrame(newsgroup_counts.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "    \n",
    "    return words['phone'].sum()\n",
    "\n",
    "q6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quest√£o 7\n",
    "\n",
    "Aplique `TfidfVectorizer` ao _data set_ `newsgroups` e descubra o TF-IDF da palavra _phone_. Responda como um √∫nico escalar arredondado para tr√™s casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.888"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def q7():\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    newsgroups_tfidf_vectorized = tfidf_vectorizer.fit_transform(newsgroup.data)\n",
    "    newsgroups_tfidf = pd.DataFrame(newsgroups_tfidf_vectorized.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "    newsgroups_tfidf_phone = round(newsgroups_tfidf['phone'].sum(), 3)\n",
    "    return float(newsgroups_tfidf_phone)\n",
    "\n",
    "q7()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
